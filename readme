I. create model: 

on data: s1000

1) create all prompts
./myScripts/combineAllPrompts.sh /Users/joro/Documents/Phd/UPF/voxforge/auto/train/wav/ /Users/joro/Documents/Phd/UPF/voxforge/auto/train/s1000.prompts

2) create dict file: 

TRAIN_DIR_WITH_PHN_AND_WRD_FILES=/Users/joro/Documents/Phd/UPF/METUdata/alignments/s1000/

/Users/joro/Documents/Phd/UPF/voxforge/myScripts/2phoneDict.sh  $DIR_WITH_PHN_AND_WRD_FILES 0 blah blah
NOTE: output is DIR_WITH_PHN_AND_WRD_FILES/all.lexicon

Then HTK_Script
with MFCC_0_D_N_Z


step 4: grapheme2phoneme conversion:
with HLEd . Result is ./interim_files/phones1.mlf

step 7 - DONE because HVIte requires sp models


step 8 - will be not done at all. in turkish there only one possible pronunciation per word.


only monophone models are used. No triphone models needed because in singing only vocals are bearing tones. The consonants in context do not influence vocals. The diphtongues do not exist in turkish language (expect for yu, ya).   

reached: sil models are done. 


II. ADAPTATION: 
(input and output are in folder /Users/joro/Documents/Phd/UPF/voxforge/auto
/adaptation)

-1) 
# dir should have .wav .txt and files with for each file to be adapted 
# prepare .txt just all words in METUbet script,
ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES=/Users/joro/Documents/Phd/UPF/Turkey-makam/




1) create dict file. mix speech dict and adaptation dict: 

TRAIN_DIR_WITH_PHN_AND_WRD_FILES=/Users/joro/Documents/Phd/UPF/METUdata/alignments/s1000/

/Users/joro/Documents/Phd/UPF/voxforge/myScripts/turkishLyrics2phoneDict.sh  $ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES 1  ${TRAIN_DIR_WITH_PHN_AND_WRD_FILES}/all.lexicon ${ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES}/lexicon.adapted

# do manually: delete SIL (with capital letters) and SILSIL from /Users/joro/Documents/Phd/UPF/voxforge/auto/scripts/interim_files/monophones1

2) prepare phoneme-level mlf
python /Users/joro/Documents/Phd/UPF/voxforge/myScripts/utils/sonicVisTextPhnDir2mlf.py $ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES ${ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES}/all.phn.mlf


3) adapt
$UPF/voxforge/myScripts/buildAdaptedModel.sh  ${ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES}  ${ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES}/lexicon.adapted ${ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES}/all.phn.mlf  ${ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES}/adaptedModel 


resulting new model: 
${ADAPTATION_DIR_WITH_PHN_AND_WRD_FILES}/adaptedModel/hmmdefs.gmllrmean





III. ALIGNMENT: 

1) prepare annoatation: 

 conver  turkish to METUBET
for i in `ls *.txtTur`; do a=`basename $i .txtTur` ;   python /Users/joro/Documents/Phd/UPF/voxforge/myScripts/utils/turkishLyrics2METULyrics.py $i ${a}.txt ; done

TODO: script for evaluation

------------------------------------------------------------



4) run forced alignment step  only: with HVite: 

 /Users/joro/Documents/Phd/UPF/voxforge/myScripts/doForceAligment.sh <FILENAME_NOEXT> /tmp/lexicon2  ~/Downloads/phoneme-level.out.mlf

NOTE: For output file phonemeLevel.mlf -o suppresses probability (S), words (W)


TODO: 
1) add noise background models
2) Are they optional now? add optional silence models between words. how? 
3) instead of GMMs see tutorial for DBN (Rolf). first see jeff hintons video.
